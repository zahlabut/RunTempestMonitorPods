#!/usr/bin/env python3
"""
Generated by Cursor AI Assistant
https://cursor.sh

OpenStack Tempest Test Runner with Pod Monitoring

This tool runs OpenStack Tempest tests via OpenShift Custom Resources
in parallel and monitors pod metrics (CPU, RAM, status) throughout the test runs.
"""

import argparse
import logging
import sys
import time
import yaml
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Tuple
import signal
import threading

from pod_monitor import PodMonitor
from cr_handler import CRHandler
from csv_exporter import CSVExporter


# Global flag for graceful shutdown
shutdown_flag = threading.Event()


def setup_logging(log_level: str, log_file: str):
    """Setup logging configuration."""
    numeric_level = getattr(logging, log_level.upper(), logging.INFO)
    
    # Create formatters
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    console_formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # File handler
    file_handler = logging.FileHandler(log_file)
    file_handler.setLevel(numeric_level)
    file_handler.setFormatter(file_formatter)
    
    # Console handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(numeric_level)
    console_handler.setFormatter(console_formatter)
    
    # Root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(numeric_level)
    root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)


def load_config(config_file: str) -> Dict:
    """Load configuration from YAML file."""
    try:
        with open(config_file, 'r') as f:
            config = yaml.safe_load(f)
        return config
    except FileNotFoundError:
        logging.error(f"Configuration file not found: {config_file}")
        sys.exit(1)
    except yaml.YAMLError as e:
        logging.error(f"Error parsing configuration file: {e}")
        sys.exit(1)


def signal_handler(signum, frame):
    """Handle interrupt signals for graceful shutdown."""
    logging.info("Received interrupt signal. Initiating graceful shutdown...")
    shutdown_flag.set()


def run_cr_with_monitoring(cr_file: str, cr_handler: CRHandler, iteration: int) -> Dict:
    """
    Run a single CR and monitor until completion.
    
    Args:
        cr_file: Path to CR file
        cr_handler: CRHandler instance
        iteration: Current iteration number
        
    Returns:
        Dictionary with test results
    """
    logger = logging.getLogger(__name__)
    
    # Apply the CR
    success, cr_name, error = cr_handler.apply_cr(cr_file)
    
    if not success:
        logger.error(f"Failed to apply CR {cr_file}: {error}")
        return {
            "cr_name": cr_file,
            "passed": False,
            "phase": "ApplyFailed",
            "tests_passed": 0,
            "tests_failed": 0,
            "tests_skipped": 0,
            "message": error,
            "timestamp": datetime.now().isoformat(),
            "iteration": iteration
        }
    
    logger.info(f"[Iteration {iteration}] Started CR: {cr_name} from {cr_file}")
    
    # Wait for completion (non-blocking, returns after timeout or completion)
    # Pass shutdown_flag to allow graceful interruption
    success, message = cr_handler.wait_for_completion(cr_name, poll_interval=30, shutdown_flag=shutdown_flag)
    
    # Check results
    results = cr_handler.check_test_results(cr_name)
    results["iteration"] = iteration
    
    if not success:
        logger.error(f"[Iteration {iteration}] CR {cr_name} failed: {message}")
    else:
        logger.info(f"[Iteration {iteration}] CR {cr_name} completed successfully")
    
    return results


def monitor_pods_loop(pod_monitor: PodMonitor, csv_exporter: CSVExporter, interval: int):
    """
    Continuously monitor pods in a separate thread.
    
    Args:
        pod_monitor: PodMonitor instance
        csv_exporter: CSVExporter instance
        interval: Monitoring interval in seconds
    """
    logger = logging.getLogger(__name__)
    logger.info("Started pod monitoring loop")
    
    while not shutdown_flag.is_set():
        try:
            # Collect metrics
            metrics = pod_monitor.collect_metrics()
            
            if metrics:
                logger.debug(f"Collected metrics for {len(metrics)} pods")
                # Export to CSV
                csv_exporter.export_metrics(metrics)
            
            # Wait for next interval
            shutdown_flag.wait(timeout=interval)
            
        except Exception as e:
            logger.error(f"Error in monitoring loop: {e}")
            time.sleep(interval)
    
    logger.info("Pod monitoring loop stopped")


def run_tests_in_loop(cr_files: List[str], cr_handler: CRHandler, csv_exporter: CSVExporter, 
                      end_time: datetime, max_parallel: int = 2) -> List[Dict]:
    """
    Run CR tests in a loop until end_time.
    
    Args:
        cr_files: List of CR files to run
        cr_handler: CRHandler instance
        csv_exporter: CSVExporter instance
        end_time: Time to stop running tests
        max_parallel: Maximum parallel CR executions
        
    Returns:
        List of all test results
    """
    logger = logging.getLogger(__name__)
    all_results = []
    iteration = 1
    
    logger.info(f"Starting test loop with {len(cr_files)} CR files")
    logger.info(f"Will run until: {end_time}")
    
    while datetime.now() < end_time and not shutdown_flag.is_set():
        logger.info(f"\n{'='*60}")
        logger.info(f"Starting iteration {iteration}")
        logger.info(f"{'='*60}\n")
        
        # Run CRs in parallel
        with ThreadPoolExecutor(max_workers=max_parallel) as executor:
            futures = {}
            
            for cr_file in cr_files:
                if shutdown_flag.is_set():
                    break
                    
                future = executor.submit(run_cr_with_monitoring, cr_file, cr_handler, iteration)
                futures[future] = cr_file
            
            # Collect results as they complete
            for future in as_completed(futures):
                if shutdown_flag.is_set():
                    break
                    
                cr_file = futures[future]
                try:
                    result = future.result()
                    all_results.append(result)
                    
                    # Export result immediately
                    csv_exporter.export_test_results([result])
                    
                    # Log result
                    status = "PASSED" if result["passed"] else "FAILED"
                    logger.info(f"[Iteration {iteration}] {cr_file}: {status}")
                    
                except Exception as e:
                    logger.error(f"[Iteration {iteration}] Exception running {cr_file}: {e}")
                    all_results.append({
                        "cr_name": cr_file,
                        "passed": False,
                        "phase": "Exception",
                        "tests_passed": 0,
                        "tests_failed": 0,
                        "tests_skipped": 0,
                        "message": str(e),
                        "timestamp": datetime.now().isoformat(),
                        "iteration": iteration
                    })
        
        iteration += 1
        
        # Check if we should continue
        remaining_time = (end_time - datetime.now()).total_seconds()
        if remaining_time <= 0:
            logger.info("Time limit reached")
            break
        
        if shutdown_flag.is_set():
            logger.info("Shutdown requested")
            break
    
    logger.info(f"\nCompleted {iteration - 1} iterations")
    return all_results


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description='Run OpenStack Tempest tests with pod monitoring'
    )
    parser.add_argument(
        '-c', '--config',
        default='config.yaml',
        help='Path to configuration file (default: config.yaml)'
    )
    args = parser.parse_args()
    
    # Load configuration
    config = load_config(args.config)
    
    # Setup logging
    setup_logging(
        config['logging']['level'],
        config['logging']['log_file']
    )
    
    logger = logging.getLogger(__name__)
    logger.info("="*60)
    logger.info("OpenStack Tempest Test Runner Started")
    logger.info("="*60)
    
    # Setup signal handlers for graceful shutdown
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # Initialize components
    pod_monitor = PodMonitor(
        namespace=config['monitoring']['namespace'],
        pod_patterns=config['monitoring']['pod_patterns'],
        interval=config['monitoring']['interval_seconds']
    )
    
    cr_handler = CRHandler(
        namespace=config['openshift']['cr_namespace'],
        timeout=config['openshift']['cr_timeout']
    )
    
    csv_exporter = CSVExporter(
        results_dir=config['output']['results_dir'],
        csv_filename=config['output']['csv_filename'],
        enable_graphs=config['output']['enable_graphs'],
        graph_format=config['output']['graph_format']
    )
    
    # Calculate end time
    end_time = datetime.now() + timedelta(hours=config['time_to_run_hours'])
    logger.info(f"Will run tests until: {end_time}")
    
    # Start pod monitoring in background thread
    monitor_thread = threading.Thread(
        target=monitor_pods_loop,
        args=(pod_monitor, csv_exporter, config['monitoring']['interval_seconds']),
        daemon=True
    )
    monitor_thread.start()
    
    # Run tests in loop
    try:
        all_results = run_tests_in_loop(
            cr_files=config['cr_files'],
            cr_handler=cr_handler,
            csv_exporter=csv_exporter,
            end_time=end_time,
            max_parallel=len(config['cr_files'])  # Run all CRs in parallel
        )
        
        # Wait a bit for final metrics to be collected
        logger.info("Waiting for final metrics collection...")
        time.sleep(config['monitoring']['interval_seconds'] + 5)
        
    finally:
        # Signal monitoring thread to stop
        shutdown_flag.set()
        monitor_thread.join(timeout=10)
        
        # Generate graphs
        if config['output']['enable_graphs']:
            logger.info("Generating graphs...")
            graph_files = csv_exporter.generate_graphs()
            for graph_file in graph_files:
                logger.info(f"Generated graph: {graph_file}")
        
        # Print summary
        logger.info("\n" + "="*60)
        logger.info("TEST RUN SUMMARY")
        logger.info("="*60)
        logger.info(f"Total test runs: {len(all_results)}")
        
        if all_results:
            passed = sum(1 for r in all_results if r['passed'])
            failed = sum(1 for r in all_results if not r['passed'])
            logger.info(f"Passed: {passed}")
            logger.info(f"Failed: {failed}")
            logger.info(f"Success rate: {passed/len(all_results)*100:.1f}%")
        
        logger.info(f"\nMetrics CSV: {csv_exporter.metrics_csv}")
        logger.info(f"Results CSV: {csv_exporter.results_csv}")
        logger.info("="*60)
        logger.info("OpenStack Tempest Test Runner Completed")
        logger.info("="*60)


if __name__ == "__main__":
    main()

