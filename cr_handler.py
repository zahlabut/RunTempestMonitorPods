"""
Generated by Cursor AI Assistant
https://cursor.sh

Custom Resource handler for managing OpenStack Tempest test CRs.
"""

import logging
import subprocess
import json
import time
from datetime import datetime
from typing import Dict, Optional, Tuple
import threading
import yaml

logger = logging.getLogger(__name__)


class CRHandler:
    """Handles Custom Resource operations for Tempest tests."""
    
    def __init__(self, namespace: str, timeout: int = 3600):
        """
        Initialize the CR handler.
        
        Args:
            namespace: Kubernetes namespace for CRs
            timeout: Timeout for CR completion in seconds
        """
        self.namespace = namespace
        self.timeout = timeout
        self.active_crs = {}  # Track active CRs
        
    def apply_cr(self, cr_file: str) -> Tuple[bool, Optional[str], Optional[str]]:
        """
        Apply a Custom Resource file.
        
        Args:
            cr_file: Path to the CR YAML file
            
        Returns:
            Tuple of (success, cr_name, error_message)
        """
        try:
            # Read CR file to extract name
            with open(cr_file, 'r') as f:
                cr_data = yaml.safe_load(f)
            
            cr_name = cr_data.get("metadata", {}).get("name", "unknown")
            cr_kind = cr_data.get("kind", "unknown")
            
            logger.info(f"Applying CR from {cr_file} (name: {cr_name}, kind: {cr_kind})")
            
            cmd = ["oc", "apply", "-f", cr_file, "-n", self.namespace]
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            
            logger.info(f"Successfully applied CR: {result.stdout.strip()}")
            
            # Track the CR
            self.active_crs[cr_name] = {
                "file": cr_file,
                "kind": cr_kind,
                "start_time": datetime.now(),
                "status": "Running"
            }
            
            return True, cr_name, None
            
        except FileNotFoundError:
            error_msg = f"CR file not found: {cr_file}"
            logger.error(error_msg)
            return False, None, error_msg
        except subprocess.CalledProcessError as e:
            error_msg = f"Failed to apply CR {cr_file}: {e.stderr}"
            logger.error(error_msg)
            return False, None, error_msg
        except Exception as e:
            error_msg = f"Unexpected error applying CR {cr_file}: {str(e)}"
            logger.error(error_msg)
            return False, None, error_msg
    
    def wait_for_pod_to_start(self, cr_name: str, timeout: int = 180, 
                              shutdown_flag: Optional[threading.Event] = None) -> Tuple[bool, str]:
        """
        Wait for a pod associated with the CR to start running.
        
        Args:
            cr_name: Name of the CR
            timeout: Timeout in seconds to wait for pod to start (default: 180s = 3min)
            shutdown_flag: Optional shutdown event to allow graceful interruption
            
        Returns:
            Tuple of (success, message)
        """
        start_time = time.time()
        poll_interval = 5  # Check every 5 seconds
        
        logger.info(f"Waiting for pod to start for CR: {cr_name} (timeout: {timeout}s)")
        
        while time.time() - start_time < timeout:
            # Check for shutdown request
            if shutdown_flag and shutdown_flag.is_set():
                msg = f"Pod startup check interrupted by shutdown"
                logger.info(msg)
                return False, msg
            
            try:
                # Get pods matching the CR name pattern
                cmd = ["oc", "get", "pods", "-n", self.namespace, "-o", "json"]
                result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                pods_data = json.loads(result.stdout)
                
                # Look for pods that match the CR name
                for pod in pods_data.get("items", []):
                    pod_name = pod["metadata"]["name"]
                    
                    if cr_name in pod_name:
                        phase = pod.get("status", {}).get("phase", "Unknown")
                        
                        # Check if pod is Running or Succeeded
                        if phase in ["Running", "Succeeded"]:
                            msg = f"Pod {pod_name} is {phase}"
                            logger.info(msg)
                            return True, msg
                        
                        # Check if pod is Failed
                        elif phase == "Failed":
                            container_statuses = pod.get("status", {}).get("containerStatuses", [])
                            reason = "Unknown"
                            if container_statuses:
                                reason = container_statuses[0].get("state", {}).get("terminated", {}).get("reason", "Unknown")
                            
                            msg = f"Pod {pod_name} failed to start (Phase: {phase}, Reason: {reason})"
                            logger.error(msg)
                            return False, msg
                        
                        # Pod exists but not running yet
                        logger.debug(f"Pod {pod_name} is in phase: {phase}")
                
            except subprocess.CalledProcessError as e:
                logger.debug(f"Failed to get pods: {e.stderr}")
            except json.JSONDecodeError as e:
                logger.debug(f"Failed to parse pods JSON: {e}")
            
            # Wait before next check
            if shutdown_flag:
                if shutdown_flag.wait(timeout=poll_interval):
                    msg = f"Pod startup check interrupted by shutdown"
                    logger.info(msg)
                    return False, msg
            else:
                time.sleep(poll_interval)
        
        # Timeout reached
        msg = f"Timeout waiting for pod to start for CR: {cr_name} (waited {timeout}s)"
        logger.error(msg)
        return False, msg
    
    def get_cr_status(self, cr_name: str, kind: str = None) -> Dict:
        """
        Get the status of a Custom Resource.
        
        Args:
            cr_name: Name of the CR
            kind: Kind of the CR (optional, will try to detect)
            
        Returns:
            Dictionary with CR status information
        """
        try:
            # If kind is not provided, try to get it from active_crs
            if kind is None and cr_name in self.active_crs:
                kind = self.active_crs[cr_name]["kind"]
            
            # Try different common resource types if kind is unknown
            resource_types = [kind] if kind else ["tempest", "tempestrun", "test"]
            
            for res_type in resource_types:
                if not res_type:
                    continue
                    
                try:
                    cmd = ["oc", "get", res_type, cr_name, "-n", self.namespace, "-o", "json"]
                    result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                    cr_data = json.loads(result.stdout)
                    
                    status = cr_data.get("status", {})
                    phase = status.get("phase", status.get("state", "Unknown"))
                    
                    # Also check pod status - if pod is in Error, test is done
                    pod_completed = self._check_pod_completion(cr_name)
                    
                    # Consider completed if either CR says so OR pod is in terminal state
                    is_completed = self._is_completed(status) or pod_completed
                    
                    return {
                        "phase": phase,
                        "completed": is_completed,
                        "succeeded": self._is_succeeded(status) and not pod_completed,
                        "message": status.get("message", ""),
                        "raw_status": status
                    }
                except subprocess.CalledProcessError:
                    continue
            
            logger.warning(f"Could not find CR {cr_name} with any known resource type")
            return {
                "phase": "NotFound",
                "completed": False,
                "succeeded": False,
                "message": "CR not found",
                "raw_status": {}
            }
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse CR status for {cr_name}: {e}")
            return {
                "phase": "Error",
                "completed": False,
                "succeeded": False,
                "message": "Failed to parse status",
                "raw_status": {}
            }
    
    def _check_pod_completion(self, cr_name: str) -> bool:
        """
        Check if pods associated with the CR are in terminal state (Error, Completed).
        
        Args:
            cr_name: Name of the CR
            
        Returns:
            True if pod is in terminal state (Error/Completed), False otherwise
        """
        try:
            cmd = ["oc", "get", "pods", "-n", self.namespace, "-o", "json"]
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            pods_data = json.loads(result.stdout)
            
            # Look for pods matching the CR name
            for pod in pods_data.get("items", []):
                pod_name = pod["metadata"]["name"]
                
                if cr_name in pod_name:
                    phase = pod.get("status", {}).get("phase", "Unknown")
                    logger.debug(f"Found pod {pod_name} for CR {cr_name} with phase: {phase}")
                    
                    # Terminal states: Error, Failed, Succeeded
                    if phase in ["Error", "Failed", "Succeeded"]:
                        logger.info(f"Pod {pod_name} is in terminal state: {phase} - marking CR as completed")
                        return True
            
            return False
            
        except Exception as e:
            logger.debug(f"Failed to check pod completion for {cr_name}: {e}")
            return False
    
    def wait_for_completion(self, cr_name: str, poll_interval: int = 30, 
                           shutdown_flag: Optional[threading.Event] = None) -> Tuple[bool, str]:
        """
        Wait for a CR to complete.
        
        Args:
            cr_name: Name of the CR
            poll_interval: Polling interval in seconds
            shutdown_flag: Optional shutdown event to allow graceful interruption
            
        Returns:
            Tuple of (success, message)
        """
        start_time = time.time()
        
        while time.time() - start_time < self.timeout:
            # Check for shutdown request
            if shutdown_flag and shutdown_flag.is_set():
                msg = f"CR {cr_name} monitoring interrupted by shutdown"
                logger.info(msg)
                return False, msg
            
            status = self.get_cr_status(cr_name)
            
            if status["completed"]:
                if status["succeeded"]:
                    msg = f"CR {cr_name} completed successfully"
                    logger.info(msg)
                    return True, msg
                else:
                    msg = f"CR {cr_name} completed with failure (phase: {status['phase']}): {status['message']}"
                    logger.warning(msg)
                    return False, msg
            
            logger.info(f"CR {cr_name} still running (phase: {status['phase']}, completed: {status['completed']})")
            
            # Use shutdown_flag.wait() if available to allow interruption
            if shutdown_flag:
                if shutdown_flag.wait(timeout=poll_interval):
                    # Shutdown was signaled during wait
                    msg = f"CR {cr_name} monitoring interrupted by shutdown"
                    logger.info(msg)
                    return False, msg
            else:
                time.sleep(poll_interval)
        
        msg = f"CR {cr_name} timed out after {self.timeout} seconds"
        logger.error(msg)
        return False, msg
    
    def check_test_results(self, cr_name: str) -> Dict:
        """
        Check the test results from a completed CR.
        
        Args:
            cr_name: Name of the CR
            
        Returns:
            Dictionary with test results
        """
        status = self.get_cr_status(cr_name)
        
        # Try to extract test results from status
        raw_status = status.get("raw_status", {})
        
        results = {
            "cr_name": cr_name,
            "passed": status["succeeded"],
            "phase": status["phase"],
            "message": status["message"],
            "tests_passed": raw_status.get("testsPassed", 0),
            "tests_failed": raw_status.get("testsFailed", 0),
            "tests_skipped": raw_status.get("testsSkipped", 0),
            "timestamp": datetime.now().isoformat()
        }
        
        return results
    
    def delete_cr(self, cr_name: str) -> bool:
        """
        Delete a Custom Resource using its original file.
        
        Args:
            cr_name: Name of the CR
            
        Returns:
            True if successful, False otherwise
        """
        try:
            # Get the CR file from active tracking
            if cr_name in self.active_crs:
                cr_file = self.active_crs[cr_name]["file"]
                
                # Delete using the original file (proper way - cleans up all resources)
                cmd = ["oc", "delete", "-f", cr_file, "-n", self.namespace, "--ignore-not-found"]
                result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                logger.info(f"Deleted CR {cr_name} using file {cr_file}: {result.stdout.strip()}")
                
                # Remove from active tracking
                del self.active_crs[cr_name]
                return True
            else:
                # Fallback: try to delete by resource type if we don't have the file
                logger.warning(f"CR {cr_name} not in active tracking, trying fallback deletion")
                resource_types = ["tempest", "tempestrun", "test"]
                
                for res_type in resource_types:
                    try:
                        cmd = ["oc", "delete", res_type, cr_name, "-n", self.namespace, "--ignore-not-found"]
                        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
                        logger.info(f"Deleted CR {cr_name}: {result.stdout.strip()}")
                        return True
                    except subprocess.CalledProcessError:
                        continue
                
                logger.warning(f"Could not delete CR {cr_name}")
                return False
            
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to delete CR {cr_name}: {e.stderr}")
            return False
        except Exception as e:
            logger.error(f"Failed to delete CR {cr_name}: {e}")
            return False
    
    def _is_completed(self, status: Dict) -> bool:
        """Check if CR is completed based on status."""
        phase = status.get("phase", status.get("state", "")).lower()
        return phase in ["succeeded", "failed", "complete", "completed", "error"]
    
    def _is_succeeded(self, status: Dict) -> bool:
        """Check if CR succeeded based on status."""
        phase = status.get("phase", status.get("state", "")).lower()
        return phase in ["succeeded", "complete", "completed"] and status.get("error", "") == ""

