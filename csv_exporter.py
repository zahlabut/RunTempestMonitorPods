"""
Generated by Cursor AI Assistant
https://cursor.sh

CSV exporter and graph plotting module for test results and metrics.
"""

import logging
import os
import csv
import glob
import zipfile
from datetime import datetime
from typing import List, Dict
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots

logger = logging.getLogger(__name__)


class CSVExporter:
    """Exports metrics and results to CSV and generates graphs."""
    
    def __init__(self, results_dir: str, csv_filename: str, enable_graphs: bool = True, graph_format: str = "png"):
        """
        Initialize the CSV exporter.
        
        Args:
            results_dir: Directory to save results
            csv_filename: Base filename for CSV (timestamp will be added)
            enable_graphs: Whether to generate graphs
            graph_format: Graph output format (png, svg, pdf)
        """
        self.results_dir = results_dir
        self.csv_filename = csv_filename
        self.enable_graphs = enable_graphs
        self.graph_format = graph_format
        
        # Create results directory if it doesn't exist
        os.makedirs(results_dir, exist_ok=True)
        
        # Archive old results if any exist
        self._archive_old_results()
        
        # Generate timestamped filenames
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.timestamp = timestamp
        self.metrics_csv = os.path.join(results_dir, f"{csv_filename}_metrics_{timestamp}.csv")
        self.results_csv = os.path.join(results_dir, f"{csv_filename}_results_{timestamp}.csv")
        self.failed_tests_csv = os.path.join(results_dir, f"{csv_filename}_failed_tests_{timestamp}.csv")
        self.test_execution_csv = os.path.join(results_dir, f"{csv_filename}_test_execution_times_{timestamp}.csv")
        self.archive_zip = os.path.join(results_dir, f"results_archive_{timestamp}.zip")
        
    def export_metrics(self, metrics: List[Dict]) -> str:
        """
        Export pod metrics to CSV.
        
        Args:
            metrics: List of metric dictionaries
            
        Returns:
            Path to the created CSV file
        """
        if not metrics:
            logger.warning("No metrics to export")
            return ""
        
        try:
            # Define CSV headers
            headers = ["timestamp", "pod_name", "phase", "ready", "restarts", "cpu", "memory"]
            
            file_exists = os.path.exists(self.metrics_csv)
            
            with open(self.metrics_csv, 'a', newline='') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=headers)
                
                if not file_exists:
                    writer.writeheader()
                
                for metric in metrics:
                    writer.writerow({k: metric.get(k, "") for k in headers})
            
            logger.info(f"Exported {len(metrics)} metric entries to {self.metrics_csv}")
            return self.metrics_csv
            
        except Exception as e:
            logger.error(f"Failed to export metrics to CSV: {e}")
            return ""
    
    def export_test_results(self, results: List[Dict]) -> str:
        """
        Export test results to CSV.
        
        Args:
            results: List of test result dictionaries
            
        Returns:
            Path to the created CSV file
        """
        if not results:
            logger.warning("No test results to export")
            return ""
        
        try:
            # Define CSV headers
            headers = ["timestamp", "cr_name", "passed", "phase", "tests_passed", "tests_failed", "tests_skipped", "message"]
            
            file_exists = os.path.exists(self.results_csv)
            
            with open(self.results_csv, 'a', newline='') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=headers)
                
                if not file_exists:
                    writer.writeheader()
                
                for result in results:
                    writer.writerow({k: result.get(k, "") for k in headers})
            
            logger.info(f"Exported {len(results)} test results to {self.results_csv}")
            return self.results_csv
            
        except Exception as e:
            logger.error(f"Failed to export test results to CSV: {e}")
            return ""
    
    def export_failed_tests(self, failed_tests: List[Dict]) -> str:
        """
        Export failed test details to CSV.
        
        Args:
            failed_tests: List of failed test dictionaries
            
        Returns:
            Path to the created CSV file
        """
        if not failed_tests:
            logger.debug("No failed tests to export")
            return ""
        
        try:
            # Define CSV headers
            headers = ["timestamp", "iteration", "cr_name", "pod_name", "test_number", "test_name", "duration", "logged_line"]
            
            file_exists = os.path.exists(self.failed_tests_csv)
            
            with open(self.failed_tests_csv, 'a', newline='') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=headers)
                
                if not file_exists:
                    writer.writeheader()
                
                for failed_test in failed_tests:
                    writer.writerow({k: failed_test.get(k, "") for k in headers})
            
            logger.info(f"Exported {len(failed_tests)} failed test entries to {self.failed_tests_csv}")
            return self.failed_tests_csv
            
        except Exception as e:
            logger.error(f"Failed to export failed tests to CSV: {e}")
            return ""
    
    def export_test_execution_times(self, test_executions: List[Dict]) -> str:
        """
        Export test execution times to CSV.
        
        Args:
            test_executions: List of test execution dictionaries
            
        Returns:
            Path to the CSV file
        """
        if not test_executions:
            logger.debug("No test execution times to export")
            return ""
        
        try:
            # Define CSV headers
            headers = ["timestamp", "iteration", "cr_name", "pod_name", "test_number", "test_name", "duration_seconds", "status"]
            
            file_exists = os.path.exists(self.test_execution_csv)
            
            with open(self.test_execution_csv, 'a', newline='') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=headers)
                
                if not file_exists:
                    writer.writeheader()
                
                for test_exec in test_executions:
                    writer.writerow({k: test_exec.get(k, "") for k in headers})
            
            logger.info(f"Exported {len(test_executions)} test execution entries to {self.test_execution_csv}")
            return self.test_execution_csv
            
        except Exception as e:
            logger.error(f"Failed to export test execution times to CSV: {e}")
            return ""
    
    def generate_graphs(self) -> List[str]:
        """
        Generate graphs from the exported CSV data.
        
        Returns:
            List of paths to generated graph files
        """
        if not self.enable_graphs:
            logger.info("Graph generation is disabled")
            return []
        
        graph_files = []
        
        # Generate pod metrics graphs
        if os.path.exists(self.metrics_csv):
            try:
                graph_file = self._generate_pod_metrics_graph()
                if graph_file:
                    graph_files.append(graph_file)
            except Exception as e:
                logger.error(f"Failed to generate pod metrics graph: {e}")
        
        # Generate test results graphs
        if os.path.exists(self.results_csv):
            try:
                graph_file = self._generate_test_results_graph()
                if graph_file:
                    graph_files.append(graph_file)
            except Exception as e:
                logger.error(f"Failed to generate test results graph: {e}")
        
        # Generate test execution times graph
        if os.path.exists(self.test_execution_csv):
            try:
                graph_file = self._generate_test_execution_graph()
                if graph_file:
                    graph_files.append(graph_file)
            except Exception as e:
                logger.error(f"Failed to generate test execution times graph: {e}")
        
        return graph_files
    
    def _generate_pod_metrics_graph(self) -> str:
        """Generate interactive graphs for pod metrics."""
        try:
            df = pd.read_csv(self.metrics_csv)
            
            if df.empty:
                logger.warning("No data to plot for pod metrics")
                return ""
            
            # Convert timestamp to datetime
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # Parse CPU and memory values
            df['cpu_numeric'] = df['cpu'].apply(self._parse_cpu_value)
            df['memory_numeric'] = df['memory'].apply(self._parse_memory_value)
            
            # Create subplots
            fig = make_subplots(
                rows=3, cols=1,
                subplot_titles=('Pod CPU Usage (millicores)', 'Pod Memory Usage (Mi)', 'Pod Restarts'),
                vertical_spacing=0.1
            )
            
            # Plot data for each pod
            for pod_name in df['pod_name'].unique():
                pod_data = df[df['pod_name'] == pod_name]
                
                # CPU plot
                fig.add_trace(
                    go.Scatter(x=pod_data['timestamp'], y=pod_data['cpu_numeric'],
                              mode='lines+markers', name=f'{pod_name} CPU'),
                    row=1, col=1
                )
                
                # Memory plot
                fig.add_trace(
                    go.Scatter(x=pod_data['timestamp'], y=pod_data['memory_numeric'],
                              mode='lines+markers', name=f'{pod_name} Memory', showlegend=False),
                    row=2, col=1
                )
                
                # Restarts plot
                fig.add_trace(
                    go.Scatter(x=pod_data['timestamp'], y=pod_data['restarts'],
                              mode='lines+markers', name=f'{pod_name} Restarts', showlegend=False),
                    row=3, col=1
                )
            
            # Update layout
            fig.update_layout(
                height=900,
                title_text="Pod Metrics Over Time",
                showlegend=True,
                hovermode='x unified'
            )
            
            # Update axes
            fig.update_xaxes(title_text="Time", row=3, col=1)
            fig.update_yaxes(title_text="CPU (m)", row=1, col=1)
            fig.update_yaxes(title_text="Memory (Mi)", row=2, col=1)
            fig.update_yaxes(title_text="Count", row=3, col=1)
            
            # Save graph
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            graph_file = os.path.join(self.results_dir, f"pod_metrics_{timestamp}.html")
            fig.write_html(graph_file)
            
            # Also save as static image
            if self.graph_format in ['png', 'svg', 'pdf']:
                static_file = os.path.join(self.results_dir, f"pod_metrics_{timestamp}.{self.graph_format}")
                fig.write_image(static_file)
                logger.info(f"Generated static graph: {static_file}")
            
            logger.info(f"Generated pod metrics graph: {graph_file}")
            return graph_file
            
        except Exception as e:
            logger.error(f"Error generating pod metrics graph: {e}")
            return ""
    
    def _generate_test_results_graph(self) -> str:
        """Generate graphs for test results."""
        try:
            df = pd.read_csv(self.results_csv)
            
            if df.empty:
                logger.warning("No data to plot for test results")
                return ""
            
            # Convert timestamp to datetime
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # Convert test count columns to numeric (handle any non-numeric values)
            df['tests_passed'] = pd.to_numeric(df['tests_passed'], errors='coerce').fillna(0)
            df['tests_failed'] = pd.to_numeric(df['tests_failed'], errors='coerce').fillna(0)
            df['tests_skipped'] = pd.to_numeric(df['tests_skipped'], errors='coerce').fillna(0)
            
            # Log test count data for debugging
            logger.debug(f"Test counts - Passed: {df['tests_passed'].sum()}, Failed: {df['tests_failed'].sum()}, Skipped: {df['tests_skipped'].sum()}")
            
            # Create figure with stacked bars for better readability with multiple iterations
            fig = go.Figure()
            
            # Sort by timestamp to show chronological order
            df = df.sort_values('timestamp')
            
            # Create a combined label showing iteration order
            # If multiple CRs, include CR name; if single CR, just show iteration
            if len(df['cr_name'].unique()) > 1:
                # Multiple CRs: show CR name + iteration number
                x_labels = []
                for cr_name in df['cr_name'].unique():
                    cr_mask = df['cr_name'] == cr_name
                    iteration_count = 1
                    for idx in df[cr_mask].index:
                        x_labels.append(f"{cr_name}<br>Run #{iteration_count}<br>{df.loc[idx, 'timestamp'].strftime('%H:%M')}")
                        iteration_count += 1
                # Re-create x_labels in df order
                x_labels = []
                cr_iteration_counters = {}
                for idx, row in df.iterrows():
                    cr_name = row['cr_name']
                    if cr_name not in cr_iteration_counters:
                        cr_iteration_counters[cr_name] = 0
                    cr_iteration_counters[cr_name] += 1
                    x_labels.append(f"{cr_name}<br>Run #{cr_iteration_counters[cr_name]}<br>{row['timestamp'].strftime('%H:%M')}")
            else:
                # Single CR: just show iteration numbers
                x_labels = [f"Run #{i+1}<br>{ts.strftime('%H:%M:%S')}" 
                           for i, ts in enumerate(df['timestamp'])]
            
            # Add stacked bars for better visualization with many iterations
            fig.add_trace(
                go.Bar(x=x_labels, y=df['tests_passed'], 
                       name='Passed',
                       marker_color='green',
                       text=df['tests_passed'],
                       textposition='inside',
                       hovertemplate='<b>%{x}</b><br>Passed: %{y}<extra></extra>')
            )
            fig.add_trace(
                go.Bar(x=x_labels, y=df['tests_failed'], 
                       name='Failed',
                       marker_color='red',
                       text=df['tests_failed'],
                       textposition='inside',
                       hovertemplate='<b>%{x}</b><br>Failed: %{y}<extra></extra>')
            )
            fig.add_trace(
                go.Bar(x=x_labels, y=df['tests_skipped'], 
                       name='Skipped',
                       marker_color='orange',
                       text=df['tests_skipped'],
                       textposition='inside',
                       hovertemplate='<b>%{x}</b><br>Skipped: %{y}<extra></extra>')
            )
            
            # Update layout
            fig.update_layout(
                height=600,
                title_text="Test Results Over Time (Stacked by Run)",
                xaxis_title="Test Run",
                yaxis_title="Test Count",
                showlegend=True,
                barmode='stack',  # Stack bars for clearer view with many iterations
                xaxis={'tickangle': -45}
            )
            
            # Save graph
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            graph_file = os.path.join(self.results_dir, f"test_results_{timestamp}.html")
            fig.write_html(graph_file)
            
            # Also save as static image
            if self.graph_format in ['png', 'svg', 'pdf']:
                static_file = os.path.join(self.results_dir, f"test_results_{timestamp}.{self.graph_format}")
                fig.write_image(static_file)
                logger.info(f"Generated static graph: {static_file}")
            
            logger.info(f"Generated test results graph: {graph_file}")
            return graph_file
            
        except Exception as e:
            logger.error(f"Error generating test results graph: {e}")
            return ""
    
    def _generate_test_execution_graph(self) -> str:
        """Generate graph for test execution times."""
        try:
            df = pd.read_csv(self.test_execution_csv)
            
            if df.empty:
                logger.warning("No data to plot for test execution times")
                return ""
            
            # Convert timestamp to datetime
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # Convert duration to numeric
            df['duration_seconds'] = pd.to_numeric(df['duration_seconds'], errors='coerce').fillna(0)
            
            # Normalize status values to uppercase for consistent coloring
            df['status'] = df['status'].str.upper()
            
            # Sort by test_name for better visualization
            df = df.sort_values(['test_name', 'timestamp'])
            
            # Log status distribution for debugging
            status_counts = df['status'].value_counts()
            logger.debug(f"Test execution status distribution: {status_counts.to_dict()}")
            
            # Create figure
            fig = go.Figure()
            
            # Add a bar for each test, colored by status
            color_map = {
                'PASSED': 'green',
                'OK': 'green',      # 'ok' gets normalized to 'OK'
                'FAILED': 'red',
                'SKIPPED': 'orange',
                'SKIP': 'orange'    # Alternative spelling
            }
            
            for status in df['status'].unique():
                status_data = df[df['status'] == status]
                color = color_map.get(status, 'blue')  # Default to blue for unknown statuses
                
                logger.debug(f"Plotting {len(status_data)} tests with status '{status}' in color '{color}'")
                
                fig.add_trace(go.Bar(
                    x=status_data['test_name'],
                    y=status_data['duration_seconds'],
                    name=status,
                    marker_color=color,
                    text=status_data['duration_seconds'].round(2),
                    textposition='auto',
                    hovertemplate='<b>%{x}</b><br>Duration: %{y:.2f}s<br>Status: ' + status + '<br>Iteration: %{customdata[0]}<extra></extra>',
                    customdata=status_data[['iteration']].values
                ))
            
            # Update layout
            fig.update_layout(
                title_text="Test Execution Times",
                xaxis_title="Test Name",
                yaxis_title="Duration (seconds)",
                height=600,
                showlegend=True,
                barmode='group',
                xaxis={'tickangle': -45, 'tickfont': {'size': 8}}
            )
            
            # Save graph
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            graph_file = os.path.join(self.results_dir, f"test_execution_times_{timestamp}.html")
            fig.write_html(graph_file)
            
            # Also save as static image
            if self.graph_format in ['png', 'svg', 'pdf']:
                static_file = os.path.join(self.results_dir, f"test_execution_times_{timestamp}.{self.graph_format}")
                fig.write_image(static_file)
                logger.info(f"Generated static graph: {static_file}")
            
            logger.info(f"Generated test execution times graph: {graph_file}")
            return graph_file
            
        except Exception as e:
            logger.error(f"Error generating test execution times graph: {e}")
            return ""
    
    def generate_api_performance_graph(self, api_data: dict) -> str:
        """
        Generate graph for API performance metrics.
        
        Args:
            api_data: Dictionary with API analysis results
            
        Returns:
            Path to the generated graph file
        """
        try:
            requests = api_data.get('requests', [])
            
            if not requests:
                logger.warning("No API request data to plot")
                return ""
            
            # Convert to DataFrame
            df = pd.DataFrame(requests)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df.sort_values('timestamp')
            
            # Check if we have timing data
            has_timing = (df['response_time'] > 0).any()
            timing_note = "" if has_timing else " (Timing data not available)"
            
            # Create figure with subplots
            fig = make_subplots(
                rows=3, cols=1,
                subplot_titles=(f'API Response Times Over Time{timing_note}', 'Response Code Distribution', 'Error Rate Timeline'),
                vertical_spacing=0.12,
                specs=[[{"secondary_y": False}],
                       [{"type": "bar"}],
                       [{"secondary_y": False}]]
            )
            
            # Plot 1: Response times by service
            for service in df['service'].unique():
                service_data = df[df['service'] == service]
                fig.add_trace(
                    go.Scatter(
                        x=service_data['timestamp'],
                        y=service_data['response_time'],
                        mode='markers',
                        name=f'{service.capitalize()} API',
                        marker=dict(
                            size=6,
                            color=service_data['status_code'],
                            colorscale='RdYlGn_r',  # Red for high codes, green for low
                            showscale=True,
                            colorbar=dict(title="Status Code", x=1.15)
                        ),
                        hovertemplate='<b>%{text}</b><br>Time: %{y:.3f}s<br>Status: %{marker.color}<extra></extra>',
                        text=[f"{row['method']} {row['endpoint']}" for _, row in service_data.iterrows()]
                    ),
                    row=1, col=1
                )
            
            # Plot 2: Status code distribution
            status_counts = df['status_code'].value_counts().sort_index()
            colors = ['green' if code < 400 else 'orange' if code < 500 else 'red' for code in status_counts.index]
            
            fig.add_trace(
                go.Bar(
                    x=[f"HTTP {code}" for code in status_counts.index],
                    y=status_counts.values,
                    marker_color=colors,
                    name='Status Codes',
                    showlegend=False,
                    hovertemplate='<b>%{x}</b><br>Count: %{y}<extra></extra>'
                ),
                row=2, col=1
            )
            
            # Plot 3: Error rate over time (sliding window)
            # Group by time buckets (1-minute intervals)
            df['time_bucket'] = df['timestamp'].dt.floor('1min')
            error_rate = df.groupby('time_bucket').agg({
                'is_error': ['sum', 'count']
            })
            error_rate.columns = ['errors', 'total']
            error_rate['error_rate'] = (error_rate['errors'] / error_rate['total'] * 100).fillna(0)
            
            fig.add_trace(
                go.Scatter(
                    x=error_rate.index,
                    y=error_rate['error_rate'],
                    mode='lines+markers',
                    name='Error Rate',
                    line=dict(color='red', width=2),
                    fill='tozeroy',
                    fillcolor='rgba(255, 0, 0, 0.1)',
                    hovertemplate='<b>%{x}</b><br>Error Rate: %{y:.1f}%<extra></extra>'
                ),
                row=3, col=1
            )
            
            # Update layout
            fig.update_layout(
                height=1000,
                title_text="API Performance Analysis",
                showlegend=True
            )
            
            # Update axes
            fig.update_xaxes(title_text="Time", row=1, col=1)
            fig.update_yaxes(title_text="Response Time (seconds)", row=1, col=1)
            
            fig.update_xaxes(title_text="HTTP Status Code", row=2, col=1)
            fig.update_yaxes(title_text="Request Count", row=2, col=1)
            
            fig.update_xaxes(title_text="Time", row=3, col=1)
            fig.update_yaxes(title_text="Error Rate (%)", row=3, col=1)
            
            # Save graph
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            graph_file = os.path.join(self.results_dir, f"api_performance_{timestamp}.html")
            fig.write_html(graph_file)
            
            # Also save as static image
            if self.graph_format in ['png', 'svg', 'pdf']:
                static_file = os.path.join(self.results_dir, f"api_performance_{timestamp}.{self.graph_format}")
                fig.write_image(static_file)
                logger.info(f"Generated static graph: {static_file}")
            
            logger.info(f"Generated API performance graph: {graph_file}")
            return graph_file
            
        except Exception as e:
            logger.error(f"Error generating API performance graph: {e}")
            return ""
    
    def export_api_requests(self, api_data: dict) -> str:
        """
        Export API request data to CSV.
        
        Args:
            api_data: Dictionary with API analysis results
            
        Returns:
            Path to the CSV file
        """
        requests = api_data.get('requests', [])
        
        if not requests:
            logger.debug("No API requests to export")
            return ""
        
        try:
            # Generate CSV filename
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            csv_file = os.path.join(self.results_dir, f"api_requests_{timestamp}.csv")
            
            # Define headers
            headers = ['timestamp', 'pod_name', 'service', 'method', 'endpoint', 'status_code', 'response_time', 'is_error']
            
            with open(csv_file, 'w', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=headers)
                writer.writeheader()
                
                for req in requests:
                    writer.writerow({
                        'timestamp': req['timestamp'].isoformat(),
                        'pod_name': req['pod_name'],
                        'service': req['service'],
                        'method': req['method'],
                        'endpoint': req['endpoint'],
                        'status_code': req['status_code'],
                        'response_time': req['response_time'],
                        'is_error': req['is_error']
                    })
            
            logger.info(f"Exported {len(requests)} API requests to {csv_file}")
            return csv_file
            
        except Exception as e:
            logger.error(f"Error exporting API requests: {e}")
            return ""
    
    def _parse_cpu_value(self, cpu_str: str) -> float:
        """Parse CPU value from string (e.g., '100m' -> 100)."""
        try:
            if cpu_str == "N/A" or not cpu_str:
                return 0.0
            if cpu_str.endswith('m'):
                return float(cpu_str[:-1])
            return float(cpu_str) * 1000  # Convert cores to millicores
        except (ValueError, AttributeError):
            return 0.0
    
    def _parse_memory_value(self, mem_str: str) -> float:
        """Parse memory value from string (e.g., '128Mi' -> 128)."""
        try:
            if mem_str == "N/A" or not mem_str:
                return 0.0
            
            # Remove unit and convert to Mi
            if mem_str.endswith('Ki'):
                return float(mem_str[:-2]) / 1024
            elif mem_str.endswith('Mi'):
                return float(mem_str[:-2])
            elif mem_str.endswith('Gi'):
                return float(mem_str[:-2]) * 1024
            else:
                # Assume bytes
                return float(mem_str) / (1024 * 1024)
        except (ValueError, AttributeError):
            return 0.0
    
    def _archive_old_results(self):
        """Archive old results in the results directory to a zip file."""
        import shutil
        
        try:
            # Check if there are any files to archive
            if not os.path.exists(self.results_dir):
                return
            
            files_to_archive = [f for f in os.listdir(self.results_dir) 
                               if f.endswith(('.csv', '.html', '.png', '.svg', '.pdf'))]
            
            # Check if web_report directory exists
            web_report_dir = os.path.join(self.results_dir, 'web_report')
            has_web_report = os.path.exists(web_report_dir)
            
            if not files_to_archive and not has_web_report:
                logger.debug("No old results to archive")
                return
            
            # Create archive filename
            archive_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            archive_name = os.path.join(self.results_dir, f"old_results_archive_{archive_timestamp}.zip")
            
            # Create zip file
            with zipfile.ZipFile(archive_name, 'w', zipfile.ZIP_DEFLATED) as zipf:
                # Archive individual files
                for filename in files_to_archive:
                    file_path = os.path.join(self.results_dir, filename)
                    zipf.write(file_path, filename)
                    logger.debug(f"Archived: {filename}")
                
                # Archive web_report directory if it exists
                if has_web_report:
                    for root, dirs, files in os.walk(web_report_dir):
                        for file in files:
                            file_path = os.path.join(root, file)
                            arcname = os.path.relpath(file_path, self.results_dir)
                            zipf.write(file_path, arcname)
            
            logger.info(f"Archived {len(files_to_archive)} old result files + web_report to {archive_name}")
            
            # Delete old files after archiving
            for filename in files_to_archive:
                file_path = os.path.join(self.results_dir, filename)
                os.remove(file_path)
            
            # Remove old web_report directory
            if has_web_report:
                shutil.rmtree(web_report_dir)
                logger.info("Removed old web_report directory")
                
        except Exception as e:
            logger.warning(f"Failed to archive old results: {e}")
    
    def create_results_archive(self) -> str:
        """
        Create a zip archive containing web_report contents (index.html + src/).
        
        Returns:
            Path to the created zip file
        """
        try:
            web_report_dir = os.path.join(self.results_dir, 'web_report')
            
            if not os.path.exists(web_report_dir):
                logger.warning("web_report directory does not exist, cannot create archive")
                return ""
            
            # Create zip file with contents directly (no web_report/ wrapper)
            with zipfile.ZipFile(self.archive_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
                file_count = 0
                for root, dirs, files in os.walk(web_report_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        # Create relative path from web_report dir (removes web_report/ prefix)
                        arcname = os.path.relpath(file_path, web_report_dir)
                        zipf.write(file_path, arcname)
                        file_count += 1
            
            logger.info(f"Created results archive: {self.archive_zip} ({file_count} files: index.html + src/)")
            return self.archive_zip
            
        except Exception as e:
            logger.error(f"Failed to create results archive: {e}")
            return ""
    
    def generate_web_report(self, test_summary: dict, graph_files: List[str]) -> str:
        """
        Generate a web-ready report with index.html and organized structure.
        
        Args:
            test_summary: Dictionary with test run statistics
            graph_files: List of generated graph file paths
            
        Returns:
            Path to the web report directory
        """
        import shutil
        from datetime import datetime
        
        try:
            # Create web report directory structure:
            # web_report/
            #   ‚îú‚îÄ‚îÄ index.html (at root)
            #   ‚îî‚îÄ‚îÄ src/ (all supporting files)
            web_dir = os.path.join(self.results_dir, "web_report")
            
            # Remove existing web_report directory if it exists (safety check)
            if os.path.exists(web_dir):
                shutil.rmtree(web_dir)
                logger.debug("Cleared existing web_report directory")
            
            src_dir = os.path.join(web_dir, "src")
            os.makedirs(web_dir, exist_ok=True)
            os.makedirs(src_dir, exist_ok=True)
            
            # Copy HTML graph files to src/
            html_files = []
            
            # First, copy from provided graph_files list
            for graph_file in graph_files:
                if graph_file and os.path.exists(graph_file) and graph_file.endswith('.html'):
                    basename = os.path.basename(graph_file)
                    if basename not in html_files:  # Avoid duplicates
                        dest = os.path.join(src_dir, basename)
                        shutil.copy2(graph_file, dest)
                        html_files.append(basename)
            
            # Also scan results directory for any HTML graph files (in case some were missed)
            all_html_in_results = glob.glob(os.path.join(self.results_dir, "*.html"))
            logger.debug(f"Scanning {self.results_dir} for HTML files, found: {[os.path.basename(f) for f in all_html_in_results]}")
            
            for html_file in all_html_in_results:
                basename = os.path.basename(html_file)
                # Only include graph files (pod_metrics, test_results, test_execution, api_performance)
                if any(prefix in basename for prefix in ['pod_metrics_', 'test_results_', 'test_execution_', 'api_performance_']):
                    if basename not in html_files:  # Avoid duplicates
                        dest = os.path.join(src_dir, basename)
                        shutil.copy2(html_file, dest)
                        html_files.append(basename)
                        logger.debug(f"Added {basename} to web report")
            
            if html_files:
                logger.info(f"Copied {len(html_files)} HTML graph files to web_report/src/")
                logger.debug(f"HTML files in web report: {html_files}")
            else:
                logger.warning("No HTML graph files found to include in web report")
            
            # Copy image files (PNG, SVG, PDF) to src/
            image_files = []
            for ext in ['png', 'svg', 'pdf']:
                for img_file in glob.glob(os.path.join(self.results_dir, f"*.{ext}")):
                    dest = os.path.join(src_dir, os.path.basename(img_file))
                    shutil.copy2(img_file, dest)
                    image_files.append(os.path.basename(img_file))
            
            # Copy CSV files to src/
            csv_files = []
            for csv_file in [self.metrics_csv, self.results_csv, self.failed_tests_csv, self.test_execution_csv]:
                if os.path.exists(csv_file):
                    dest = os.path.join(src_dir, os.path.basename(csv_file))
                    shutil.copy2(csv_file, dest)
                    csv_files.append(os.path.basename(csv_file))
            
            # Also copy API requests CSV if it exists
            for api_csv in glob.glob(os.path.join(self.results_dir, "api_requests_*.csv")):
                dest = os.path.join(src_dir, os.path.basename(api_csv))
                shutil.copy2(api_csv, dest)
                csv_files.append(os.path.basename(api_csv))
            
            # Generate index.html at web_report root
            index_path = os.path.join(web_dir, "index.html")
            self._generate_index_html(index_path, test_summary, html_files, csv_files, image_files)
            
            logger.info(f"Generated web report at: {web_dir}")
            return web_dir
            
        except Exception as e:
            logger.error(f"Failed to generate web report: {e}")
            return ""
    
    def _generate_index_html(self, output_path: str, test_summary: dict, 
                            html_files: List[str], csv_files: List[str], 
                            image_files: List[str]) -> None:
        """Generate the main index.html file."""
        from datetime import datetime
        
        # Get statistics (test-level, not CR-level)
        total_runs = test_summary.get('total_runs', 0)
        total_tests = test_summary.get('total_tests', 0)
        tests_passed = test_summary.get('tests_passed', 0)
        tests_failed = test_summary.get('tests_failed', 0)
        tests_skipped = test_summary.get('tests_skipped', 0)
        success_rate = (tests_passed / total_tests * 100) if total_tests > 0 else 0
        
        # Generate HTML content
        html_content = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tempest Test Results - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            padding: 20px;
            min-height: 100vh;
        }}
        
        .container {{
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
            padding: 40px;
        }}
        
        header {{
            text-align: center;
            margin-bottom: 40px;
            padding-bottom: 20px;
            border-bottom: 3px solid #667eea;
        }}
        
        h1 {{
            color: #667eea;
            font-size: 2.5em;
            margin-bottom: 10px;
        }}
        
        .subtitle {{
            color: #666;
            font-size: 1.1em;
        }}
        
        .summary {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }}
        
        .stat-card {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 10px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
            transition: transform 0.3s ease;
        }}
        
        .stat-card:hover {{
            transform: translateY(-5px);
        }}
        
        .stat-card.success {{
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        }}
        
        .stat-card.danger {{
            background: linear-gradient(135deg, #eb3349 0%, #f45c43 100%);
        }}
        
        .stat-card.info {{
            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        }}
        
        .stat-value {{
            font-size: 3em;
            font-weight: bold;
            margin-bottom: 5px;
        }}
        
        .stat-label {{
            font-size: 1em;
            opacity: 0.9;
        }}
        
        section {{
            margin-bottom: 40px;
        }}
        
        h2 {{
            color: #667eea;
            font-size: 1.8em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #e0e0e0;
        }}
        
        .grid {{
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
            gap: 20px;
        }}
        
        .card {{
            background: #f8f9fa;
            border-radius: 8px;
            padding: 20px;
            border-left: 4px solid #667eea;
            transition: all 0.3s ease;
        }}
        
        .card:hover {{
            box-shadow: 0 5px 20px rgba(0,0,0,0.1);
            transform: translateX(5px);
        }}
        
        .card h3 {{
            color: #333;
            font-size: 1.2em;
            margin-bottom: 15px;
        }}
        
        .card a {{
            display: inline-block;
            color: #667eea;
            text-decoration: none;
            padding: 10px 20px;
            background: white;
            border-radius: 5px;
            border: 2px solid #667eea;
            transition: all 0.3s ease;
            font-weight: 500;
        }}
        
        .card a:hover {{
            background: #667eea;
            color: white;
        }}
        
        .csv-icon::before {{
            content: "üìä ";
        }}
        
        .graph-icon::before {{
            content: "üìà ";
        }}
        
        .image-icon::before {{
            content: "üñºÔ∏è ";
        }}
        
        .image-preview {{
            max-width: 100%;
            margin-top: 10px;
            border-radius: 5px;
            border: 1px solid #ddd;
        }}
        
        footer {{
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 2px solid #e0e0e0;
            color: #666;
        }}
        
        .timestamp {{
            color: #999;
            font-size: 0.9em;
        }}
        
        @media (max-width: 768px) {{
            .container {{
                padding: 20px;
            }}
            
            h1 {{
                font-size: 1.8em;
            }}
            
            .stat-value {{
                font-size: 2em;
            }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üöÄ OpenStack Tempest Test Results</h1>
            <p class="subtitle">Automated Testing Report</p>
            <p class="timestamp">Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </header>
        
        <section class="summary">
            <div class="stat-card info">
                <div class="stat-value">{total_tests}</div>
                <div class="stat-label">Total Tests Executed</div>
                <div style="font-size: 0.8em; opacity: 0.8; margin-top: 5px;">{total_runs} CR run(s)</div>
            </div>
            <div class="stat-card success">
                <div class="stat-value">{tests_passed}</div>
                <div class="stat-label">Tests Passed</div>
                <div style="font-size: 0.8em; opacity: 0.8; margin-top: 5px;">Individual test successes</div>
            </div>
            <div class="stat-card danger">
                <div class="stat-value">{tests_failed}</div>
                <div class="stat-label">Tests Failed</div>
                <div style="font-size: 0.8em; opacity: 0.8; margin-top: 5px;">Requiring investigation</div>
            </div>
            <div class="stat-card" style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);">
                <div class="stat-value">{tests_skipped}</div>
                <div class="stat-label">Tests Skipped</div>
                <div style="font-size: 0.8em; opacity: 0.8; margin-top: 5px;">Not executed</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{success_rate:.1f}%</div>
                <div class="stat-label">Success Rate</div>
                <div style="font-size: 0.8em; opacity: 0.8; margin-top: 5px;">Passed / Total tests</div>
            </div>
        </section>
"""
        
        # Interactive Graphs Section
        if html_files:
            html_content += """
        <section>
            <h2>üìà Interactive Graphs</h2>
            <div class="grid">
"""
            for html_file in sorted(html_files):
                # Create friendly names
                if "pod_metrics" in html_file:
                    title = "Pod Metrics (CPU, Memory, Restarts)"
                    desc = "Monitor resource usage and stability across all pods"
                elif "test_results" in html_file:
                    title = "Test Results (Pass/Fail/Skip)"
                    desc = "Track test outcomes and counts over time"
                elif "test_execution" in html_file:
                    title = "Test Execution Times"
                    desc = "Analyze individual test performance and timing"
                elif "api_performance" in html_file:
                    title = "API Performance Analysis"
                    desc = "Response times, status codes, and error rates for API requests"
                else:
                    title = html_file.replace('.html', '').replace('_', ' ').title()
                    desc = "Interactive visualization"
                
                html_content += f"""
                <div class="card">
                    <h3 class="graph-icon">{title}</h3>
                    <p style="color: #666; margin-bottom: 15px;">{desc}</p>
                    <a href="src/{html_file}" target="_blank">Open Graph ‚Üí</a>
                </div>
"""
            html_content += """
            </div>
        </section>
"""
        
        # CSV Data Files Section
        if csv_files:
            html_content += """
        <section>
            <h2>üìä CSV Data Files</h2>
            <div class="grid">
"""
            for csv_file in sorted(csv_files):
                # Create friendly names and descriptions
                if "metrics" in csv_file:
                    title = "Pod Metrics Data"
                    desc = "CPU, memory, and restart counts for all monitored pods"
                elif "results" in csv_file and "failed" not in csv_file and "execution" not in csv_file:
                    title = "Test Results Summary"
                    desc = "Pass/fail status and test counts per iteration"
                elif "failed_tests" in csv_file:
                    title = "Failed Tests Details"
                    desc = "Detailed breakdown of all failed tests with timing"
                elif "execution_times" in csv_file:
                    title = "Test Execution Times"
                    desc = "Duration and status for every individual test"
                elif "api_requests" in csv_file:
                    title = "API Requests Data"
                    desc = "All API requests with timestamps, response codes, and timing"
                else:
                    title = csv_file.replace('.csv', '').replace('_', ' ').title()
                    desc = "Raw data export"
                
                html_content += f"""
                <div class="card">
                    <h3 class="csv-icon">{title}</h3>
                    <p style="color: #666; margin-bottom: 15px;">{desc}</p>
                    <a href="src/{csv_file}" download>Download CSV ‚Üí</a>
                </div>
"""
            html_content += """
            </div>
        </section>
"""
        
        # Static Images Section
        if image_files:
            html_content += """
        <section>
            <h2>üñºÔ∏è Static Images</h2>
            <div class="grid">
"""
            for image_file in sorted(image_files):
                # Only show PNG images with previews
                if image_file.endswith('.png'):
                    title = image_file.replace('.png', '').replace('_', ' ').title()
                    html_content += f"""
                <div class="card">
                    <h3 class="image-icon">{title}</h3>
                    <a href="src/{image_file}" download>Download ‚Üí</a>
                    <img src="src/{image_file}" alt="{title}" class="image-preview">
                </div>
"""
                else:
                    title = image_file.replace(os.path.splitext(image_file)[1], '').replace('_', ' ').title()
                    html_content += f"""
                <div class="card">
                    <h3 class="image-icon">{title}</h3>
                    <a href="src/{image_file}" download>Download {os.path.splitext(image_file)[1].upper()} ‚Üí</a>
                </div>
"""
            html_content += """
            </div>
        </section>
"""
        
        # Footer
        html_content += """
        <footer>
            <p><strong>OpenStack Tempest Test Runner</strong></p>
            <p style="margin-top: 10px;">Automated testing with comprehensive pod monitoring and metrics collection</p>
            <p style="margin-top: 10px; color: #999;">Generated by RunTempestMonitorPods</p>
        </footer>
    </div>
</body>
</html>
"""
        
        # Write to file
        with open(output_path, 'w') as f:
            f.write(html_content)
        
        logger.info(f"Generated index.html at: {output_path}")

